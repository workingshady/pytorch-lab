{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "330faa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch and check CUDA availability\n",
    "import torch\n",
    "print(torch.__version__)  # Print PyTorch version\n",
    "print(torch.cuda.is_available())  # Check if CUDA (GPU support) is available\n",
    "print(torch.cuda.device_count())  # Number of available CUDA devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8378e5",
   "metadata": {},
   "source": [
    "# **BASICS**\n",
    "This section covers the basics of PyTorch tensors, including scalars, vectors, matrices, and higher-dimensional tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60318562",
   "metadata": {},
   "source": [
    "![Scalar, Vector, Matrix, Tensor](https://hadrienj.github.io/assets/images/2.1/scalar-vector-matrix-tensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e290fa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar tensor (0-dimensional)\n",
    "scalar = torch.tensor(7)\n",
    "scalar  # Output: tensor(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "550c44c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of dimensions of the scalar tensor\n",
    "scalar.ndim  # Output: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7be7eb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the scalar tensor\n",
    "scalar.shape  # Output: torch.Size([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a61068ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Python number from the scalar tensor\n",
    "scalar.item()  # Output: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "563a5fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector tensor (1-dimensional)\n",
    "vector = torch.tensor([7, 7])\n",
    "vector  # Output: tensor([7, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7127fe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of dimensions of the vector tensor\n",
    "vector.ndim  # Output: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a1f062bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the vector tensor\n",
    "vector.shape  # Output: torch.Size([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "60dfef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8,  8],\n",
       "        [ 9, 10,  9]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix tensor (2-dimensional)\n",
    "matrix = torch.tensor([[7, 8, 8],\n",
    "                       [9, 10, 9]])\n",
    "matrix  # Output: 2x3 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d41b57bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of dimensions of the matrix tensor\n",
    "matrix.ndim  # Output: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "8b3f2309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the matrix tensor\n",
    "matrix.shape  # Output: torch.Size([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5d227b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3D Tensor (3-dimensional)\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR  # Output: 1x3x3 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "caf75120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of dimensions of the 3D tensor\n",
    "TENSOR.ndim  # Output: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7e8b72ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the 3D tensor\n",
    "TENSOR.shape  # Output: torch.Size([1, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5b4db8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[10, 11, 12],\n",
       "         [13, 14, 15],\n",
       "         [10, 11, 12],\n",
       "         [13, 14, 15]]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4D Tensor example\n",
    "TENSOR_2 = torch.tensor([[[ 1, 2, 3],\n",
    "                          [ 4, 5, 6],\n",
    "                          [ 1, 2, 3],\n",
    "                          [ 4, 5, 6]],\n",
    "\n",
    "                         [[10, 11, 12],\n",
    "                          [13, 14, 15],\n",
    "                          [10, 11, 12],\n",
    "                          [13, 14, 15]]])\n",
    "TENSOR_2  # Output: 2x4x3 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "dab80af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of dimensions of the 4D tensor\n",
    "TENSOR_2.ndim  # Output: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ac51e1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the 4D tensor\n",
    "TENSOR_2.shape  # Output: torch.Size([2, 4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "72bc2885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[10, 11, 12],\n",
      "        [13, 14, 15],\n",
      "        [10, 11, 12],\n",
      "        [13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "# Loop through the first dimension of TENSOR_2 and print each sub-tensor\n",
    "for i in range(len(TENSOR_2)):\n",
    "    print(TENSOR_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ead551de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6])\n",
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6])\n",
      "tensor([10, 11, 12])\n",
      "tensor([13, 14, 15])\n",
      "tensor([10, 11, 12])\n",
      "tensor([13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "# Loop through the first and second dimensions of TENSOR_2 and print each row\n",
    "for i in range(len(TENSOR_2)):\n",
    "    for j in range(len(TENSOR_2[i])):\n",
    "        print(TENSOR_2[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "8fa9ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(5)\n",
      "tensor(6)\n",
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(5)\n",
      "tensor(6)\n",
      "tensor(10)\n",
      "tensor(11)\n",
      "tensor(12)\n",
      "tensor(13)\n",
      "tensor(14)\n",
      "tensor(15)\n",
      "tensor(10)\n",
      "tensor(11)\n",
      "tensor(12)\n",
      "tensor(13)\n",
      "tensor(14)\n",
      "tensor(15)\n"
     ]
    }
   ],
   "source": [
    "# Loop through all elements of TENSOR_2 and print each value\n",
    "for i in range(len(TENSOR_2)):\n",
    "    for j in range(len(TENSOR_2[i])):\n",
    "        for k in range(len(TENSOR_2[i][j])):\n",
    "            print(TENSOR_2[i][j][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6629eeb",
   "metadata": {},
   "source": [
    "# **RANDOM TENSORS**\n",
    "This section will cover how to create tensors with random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ee978ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## why random tensors?\n",
    "# Random tensors are useful for initializing weights in neural networks, data augmentation, and testing models.\n",
    "# They help in creating diverse datasets and avoiding overfitting by introducing variability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de008a4",
   "metadata": {},
   "source": [
    "# **A. Uniform Distribution**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "c288a31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0549, 0.4944, 0.2001, 0.9065],\n",
       "         [0.1843, 0.4180, 0.7188, 0.0878],\n",
       "         [0.7205, 0.3300, 0.3622, 0.5796]],\n",
       "\n",
       "        [[0.4292, 0.0443, 0.4221, 0.0352],\n",
       "         [0.6698, 0.1253, 0.6560, 0.5416],\n",
       "         [0.9315, 0.2388, 0.9832, 0.6727]]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uniform Distribution\n",
    "# 1.torch.rand(*size)\n",
    "\n",
    "random_tensor= torch.rand(2, 3, 4)  # Create a random tensor with values uniformly distributed between 0 and 1\n",
    "\n",
    "random_tensor  # Output: 2x3x4 tensor with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "173554cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "232e46f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e2329d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6, 8, 1, 1],\n",
       "         [3, 5, 9, 9],\n",
       "         [4, 2, 5, 9]],\n",
       "\n",
       "        [[8, 2, 0, 9],\n",
       "         [2, 8, 7, 5],\n",
       "         [0, 9, 7, 7]]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.randint(low, high, size)\n",
    "\n",
    "# Create a random tensor with integer values between 0 and 10\n",
    "random_int_tensor = torch.randint(0, 10, (2, 3, 4))  # 2x3x4 tensor with random integers\n",
    "random_int_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "efa5a05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor=torch.rand(3,224,224)\n",
    "\n",
    "random_image_size_tensor.shape  , random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "4e44c034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9416, 0.0735, 0.9227, 0.0393],\n",
       "         [0.8484, 0.6823, 0.3721, 0.0014],\n",
       "         [0.8630, 0.2822, 0.1260, 0.3181]],\n",
       "\n",
       "        [[0.6472, 0.4358, 0.0290, 0.2847],\n",
       "         [0.0447, 0.1374, 0.5808, 0.7987],\n",
       "         [0.1672, 0.1141, 0.1320, 0.6030]]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.rand_like(input)\n",
    "\n",
    "# Create a random tensor with the same shape as another tensor (ensure dtype is float)\n",
    "random_tensor_like = torch.rand_like(random_int_tensor, dtype=torch.float)\n",
    "\n",
    "random_tensor_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95277e",
   "metadata": {},
   "source": [
    "# **B. Normal (Gaussian) Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "0bde00d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4807, -0.9390,  0.0172,  0.1326],\n",
       "        [-0.8235, -1.4217, -0.4019, -1.9991],\n",
       "        [-1.0845,  1.0989, -0.9898, -0.1510]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.randn(*size)\n",
    "\n",
    "# Create a random tensor with values from a normal distribution (mean=0, std=1)\n",
    "\n",
    "x = torch.randn(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "628c580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ca12a2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0788, -1.6242, -0.2751],\n",
       "        [ 0.3969, -1.3153,  0.8843],\n",
       "        [ 1.1825, -0.1379,  0.7743]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.normal(mean, std, size)\n",
    "x_normal = torch.normal(mean=0., std=1., size=(3, 3))\n",
    "\n",
    "x_normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a17782",
   "metadata": {},
   "source": [
    "## **ZEROS & ONES**\n",
    "**Creating tensors filled with 0s or 1s is fundamental for:**\n",
    "\n",
    "- Weight or bias initialization.\n",
    "\n",
    "- Placeholder tensors for results.\n",
    "\n",
    "- Masks or binary flags.\n",
    "\n",
    "- Identity operations (multiplicative identity: ones; additive identity: zeros).\n",
    "\n",
    "- Pre-allocating space to be filled later (performance-friendly).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f3b0eabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0.]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(3)       # 1D vector: [0, 0, 0]\n",
    "y = torch.zeros(2, 3)    # 2x3 matrix\n",
    "z = torch.zeros(2, 3, 4)  # 2x3x4 tensor\n",
    "\n",
    "x, y, z  # Output: 1D vector, 2D matrix, and 3D tensor of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "bfda6874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 2, dtype=torch.float64, device='cuda', requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "57ed645f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]]))"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3)        # [1, 1, 1]\n",
    "y = torch.ones(2, 3)     # 2x3 of ones\n",
    "z = torch.ones(2, 3, 4)   # 2x3x4 tensor of ones\n",
    "x, y, z  # Output: 1D vector, 2D matrix, and 3D tensor of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "446d3072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], device='cuda:0', dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 2, dtype=torch.float64, device='cuda', requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ba26818b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros_like / torch.ones_like\n",
    "x_zeros_like = torch.zeros_like(x, dtype=torch.float64, device='cuda')\n",
    "x_ones_like = torch.ones_like(y, dtype=torch.float64, device='cuda')\n",
    "x_zeros_like, x_ones_like  # Output: Tensors with the same shape as x and y, filled with zeros and ones respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c48549c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 7, 7],\n",
       "        [7, 7, 7]])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.full\n",
    "## When you want to fill with any constant, use torch.full:\n",
    "\n",
    "x = torch.full((2, 3), 7)  # 2x3 tensor filled with 7s\n",
    "x  # Output: 2x3 tensor filled with 7s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df89e9",
   "metadata": {},
   "source": [
    "# **RANGE OF TENSORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "3ec41d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange(start, end, step)\n",
    "# Create a tensor with values from 0 to 10 with a step of 2\n",
    "x = torch.arange(0, 11, 2)\n",
    "x  # Output: tensor([0, 2, 4, 6, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f5854",
   "metadata": {},
   "source": [
    "# **TENSOR DATA TYPES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2048d1",
   "metadata": {},
   "source": [
    "ðŸ“Œ 1ï¸âƒ£ What is dtype?\n",
    "dtype = data type descriptor for a tensor.\n",
    "\n",
    "Defines what kind of data is stored (integers, floats, bool, complex).\n",
    "\n",
    "Controls:\n",
    "\n",
    "- Precision (bits per element)\n",
    "\n",
    "- Storage size (RAM/VRAM footprint)\n",
    "\n",
    "- Valid operations (some ops only work for floats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89537836",
   "metadata": {},
   "source": [
    "| Dtype            | PyTorch                          | Bits  | Typical Use                 |\n",
    "| ---------------- | -------------------------------- | ----- | --------------------------- |\n",
    "| 32-bit float     | `torch.float32` (`torch.float`)  | 32    | Default for DL, fast on GPU |\n",
    "| 64-bit float     | `torch.float64` (`torch.double`) | 64    | High-precision math, stats  |\n",
    "| 16-bit float     | `torch.float16` (`torch.half`)   | 16    | Mixed precision training    |\n",
    "| BF16             | `torch.bfloat16`                 | 16    | Mixed precision (CPU, TPU)  |\n",
    "| 8-bit float      | `torch.float8_e4m3fn`            | 8     | Experimental, quantization  |\n",
    "| 8-bit int        | `torch.uint8`                    | 8     | Masks, binary flags         |\n",
    "| 8-bit int signed | `torch.int8`                     | 8     | Quantized models            |\n",
    "| 16-bit int       | `torch.int16` (`torch.short`)    | 16    | Rare                        |\n",
    "| 32-bit int       | `torch.int32` (`torch.int`)      | 32    | Indices, labels             |\n",
    "| 64-bit int       | `torch.int64` (`torch.long`)     | 64    | Default for indices         |\n",
    "| Bool             | `torch.bool`                     | 1-bit | Masks, binary conditions    |\n",
    "| Complex64        | `torch.complex64`                | 64    | FFTs, signal processing     |\n",
    "| Complex128       | `torch.complex128`               | 128   | High precision complex      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ab549e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0])\n",
    "print(x.dtype)  # torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "bf3be93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2, 2, dtype=torch.float64)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ecd6f9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.int32\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2)\n",
    "\n",
    "x_fp64 = x.to(torch.float64)\n",
    "print(x_fp64.dtype)  # torch.float64\n",
    "x_int = x.to(torch.int32)\n",
    "print(x_int.dtype)  # torch.int32\n",
    "x_fp64 = x.type(torch.float64)  # same\n",
    "print(x_fp64.dtype)  # torch.float64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef5ab5",
   "metadata": {},
   "source": [
    "# **âœ… Note: `.to()` can also set device at the same time:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "2880ce3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0507,  1.5439],\n",
       "        [-0.5356, -0.8599]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(dtype=torch.float16, device='cuda')\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac09cb",
   "metadata": {},
   "source": [
    "| When                                        | Recommended dtype                   |\n",
    "| ------------------------------------------- | ----------------------------------- |\n",
    "| General DL training                         | `torch.float32`                     |\n",
    "| High-precision numerics (e.g., eigenvalues) | `torch.float64`                     |\n",
    "| Mixed precision (AMP)                       | `torch.float16` or `torch.bfloat16` |\n",
    "| Masks                                       | `torch.bool`                        |\n",
    "| Labels for classification                   | `torch.long`                        |\n",
    "| One-hot / binary mask                       | `torch.uint8` or `torch.bool`       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1cdfc893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(data=[1,2],\n",
    "             dtype=None,\n",
    "             device=None,\n",
    "             requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c6c38",
   "metadata": {},
   "source": [
    "| Parameter       | Type           | Purpose                               | Example               |\n",
    "| --------------- | -------------- | ------------------------------------- | --------------------- |\n",
    "| `data`          | array-like     | Input data (list, tuple, NumPy array) | `[1, 2, 3]`           |\n",
    "| `dtype`         | `torch.dtype`  | Explicitly set the tensorâ€™s data type | `torch.float32`       |\n",
    "| `device`        | `torch.device` | CPU or CUDA device                    | `'cpu'` or `'cuda:0'` |\n",
    "| `requires_grad` | `bool`         | Track gradients for autograd          | `True`                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d7af4",
   "metadata": {},
   "source": [
    "### Tensor datatypes \n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d94907a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # what datatype is the tensor (e.g. float32 or float16)\n",
    "                               device=None, # What device is your tensor on\n",
    "                               requires_grad=False) # whether or not to track gradients with this tensors operations\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "78b34313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4d5d4d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b6b771b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 9., 36., 81.]), torch.float32)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi=float_16_tensor * float_32_tensor\n",
    "multi,multi.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "8ae158f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_temsor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                             dtype=torch.int32,\n",
    "                             device=0)\n",
    "int_32_temsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "4f362632",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[332], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfloat_32_tensor\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mint_32_temsor\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "float_32_tensor*int_32_temsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "5d33ed79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_temsor=int_32_temsor.to(device=\"cpu\")\n",
    "int_32_temsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "af061600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor*int_32_temsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "b5b2dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of float_16_tensor: torch.Size([3])\n",
      "Dtype of float_16_tensor: torch.float16\n",
      "Device of float_16_tensor: cpu\n",
      "Size of float_16_tensor: torch.Size([3])\n",
      "Number of elements: 3\n",
      "Sum of elements: 18.0\n",
      "Mean of elements: 6.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of float_16_tensor: {float_16_tensor.shape}\")\n",
    "print(f\"Dtype of float_16_tensor: {float_16_tensor.dtype}\")\n",
    "print(f\"Device of float_16_tensor: {float_16_tensor.device}\")\n",
    "\n",
    "print(f\"Size of float_16_tensor: {float_16_tensor.size()}\")\n",
    "print(f\"Number of elements: {float_16_tensor.numel()}\")\n",
    "print(f\"Sum of elements: {float_16_tensor.sum().item()}\")\n",
    "print(f\"Mean of elements: {float_16_tensor.mean().item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd888d70",
   "metadata": {},
   "source": [
    "# **Manipulating Tensors (Tensor Operations)**\n",
    "\n",
    "### **The primary tensor operations discussed here are:**\n",
    "\n",
    "- **Addition:** Combining tensors element-wise by adding corresponding elements.\n",
    "- **Subtraction:** Combining tensors element-wise by subtracting corresponding elements.\n",
    "- **Multiplication (Element-wise)**: Multiplying corresponding elements of tensors.\n",
    "- **Division (Element-wise):** Dividing corresponding elements of tensors.\n",
    "- **Matrix Multiplication:** A linear algebra operation that combines tensors (typically 2D) to produce a new tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "6876f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "B = torch.tensor([[10, 20], [30, 40]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "da6d5049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12],\n",
      "        [13, 14]])\n",
      "tensor([[10, 20],\n",
      "        [30, 40]])\n",
      "tensor([[-9, -8],\n",
      "        [-7, -6]])\n"
     ]
    }
   ],
   "source": [
    "A_10= A + 10  # Add 10 to each element of\n",
    "print(A_10)\n",
    "\n",
    "A__10=A*10  # Multiply each element of A by 10\n",
    "print(A__10)\n",
    "\n",
    "_10_A=A -10 # Subtract 10 from each element of A\n",
    "print(_10_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "062f9ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12],\n",
      "        [13, 14]])\n",
      "tensor([[10, 20],\n",
      "        [30, 40]])\n",
      "tensor([[-9, -8],\n",
      "        [-7, -6]])\n"
     ]
    }
   ],
   "source": [
    "A_10 = A.add(10)  # Add 10 to each element of A\n",
    "print(A_10)\n",
    "\n",
    "A__10=A.mul(10)  # Multiply each element of A by 10\n",
    "print(A__10)\n",
    "\n",
    "_10_A=A.sub(10)  # Subtract 10 from each element of A\n",
    "print(_10_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e69b6ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21, 42],\n",
      "        [63, 84]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[21, 42],\n",
       "        [63, 84]])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shapes: A.shape and B.shape â€” understand what will broadcast.\n",
    "C = torch.add(A, B)\n",
    "print(C)  # Output: tensor([[11, 22], [33, 44]])\n",
    "\n",
    "\n",
    "\n",
    "# Use in-place only if you really need it:\n",
    "A.add_(B)  # modifies A in place\n",
    "A\n",
    "# Note: In-place ops can break gradients. Avoid in-place operations in gradient flow unless you know the implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22],\n",
      "        [33, 44]])\n",
      "tensor([[ -9, -18],\n",
      "        [-27, -36]])\n",
      "tensor([[ 10,  40],\n",
      "        [ 90, 160]])\n",
      "tensor([[0.1000, 0.1000],\n",
      "        [0.1000, 0.1000]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise addition\n",
    "A_plus_B = A + B  # Add corresponding elements of A and B\n",
    "print(A_plus_B)  # Output: tensor([[11, 22], [33, 44]])\n",
    "\n",
    "# Element-wise subtraction\n",
    "A_minus_B = A - B  # Subtract corresponding elements of A and B\n",
    "print(A_minus_B)  # Output: tensor([[-9, -18], [-27, -36]])\n",
    "\n",
    "# Element-wise multiplication\n",
    "A_times_B = A * B  # Multiply corresponding elements of A and B\n",
    "print(A_times_B)  # Output: tensor([[10, 40], [90, 160]])\n",
    "\n",
    "# Element-wise division\n",
    "A_div_B = A / B  # Divide corresponding elements of A by B\n",
    "print(A_div_B)  # Output: tensor([[0.1000, 0.1000], [0.1000, 0.1000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada64269",
   "metadata": {},
   "source": [
    "### Broadcasting Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea91b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 2], [3, 4]])  # shape (2, 2)\n",
    "B = torch.tensor([10, 20])          # shape (2,) --> broadcast to (2, 2)\n",
    "\n",
    "C = A + B  # [[11, 22], [13, 24]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90767c94",
   "metadata": {},
   "source": [
    "### Element-wise Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "824ec029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8, 15])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([2, 3])\n",
    "B = torch.tensor([4, 5])\n",
    "\n",
    "C = A * B  # tensor([8, 15])\n",
    "print(C)\n",
    "\n",
    "\"\"\"\n",
    "âš ï¸ Pitfalls\n",
    "Common bug: * is element-wise, not matrix multiplication.\n",
    "For matrices, A * B â‰  A @ B.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8521257f",
   "metadata": {},
   "source": [
    "![\"dot_product](https://www.mathsisfun.com/algebra/images/matrix-multiply-a.svg)\n",
    "\n",
    "### (1, 2, 3) â€¢ (7, 9, 11) = 1Ã—7 + 2Ã—9 + 3Ã—11 = 58\n",
    "\n",
    "![alt text](https://www.mathsisfun.com/algebra/images/matrix-multiply-b.svg)\n",
    "### (1, 2, 3) â€¢ (8, 10, 12) = 1Ã—8 + 2Ã—10 + 3Ã—12 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "a7346b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 55,  64],\n",
      "        [127, 154]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication(dot product)\n",
    "A = torch.tensor([[1, 2,3], [4,5, 6]]) # shape (2, 3)\n",
    "B = torch.tensor([[4, 8], [9, 10],[11,12]])  # shape (3, 2)\n",
    "\n",
    "C = torch.matmul(A, B)\n",
    "# or\n",
    "C = A @ B\n",
    "print(C)  # Output: tensor([[19, 22], [43, 50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ff2c7a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 55,  64],\n",
      "        [127, 154]])\n",
      "Execution time: 0.000000000000 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "result = torch.matmul(A, B)\n",
    "end_time = time.time()\n",
    "\n",
    "print(result)\n",
    "print(f\"Execution time: {end_time - start_time:.12f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "d782e863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product of row 0 of A and column 0 of B: 55\n",
      "Dot product of row 0 of A and column 1 of B: 64\n",
      "Dot product of row 1 of A and column 0 of B: 127\n",
      "Dot product of row 1 of A and column 1 of B: 154\n",
      "Execution time: 0.001122236252 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "# simulate matrix multiplication by for loop\n",
    "for i in range(len(A)):\n",
    "    for j in range(len(B[0])):\n",
    "        dot_product = 0\n",
    "        for k in range(len(B)):\n",
    "            dot_product += A[i][k] * B[k][j]\n",
    "        print(f\"Dot product of row {i} of A and column {j} of B: {dot_product}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.12f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e7902",
   "metadata": {},
   "source": [
    "## **1ï¸âƒ£ Theoretical Rule**\n",
    "\n",
    "**Definition:**\n",
    "Given:\n",
    "\n",
    "* Matrix **A** with shape $(m \\times k)$\n",
    "* Matrix **B** with shape $(k \\times n)$\n",
    "\n",
    "The matrix product:\n",
    "\n",
    "$$\n",
    "C = AB\n",
    "\\quad \\text{has shape} \\quad\n",
    "(m \\times n)\n",
    "$$\n",
    "\n",
    "**Key condition:**\n",
    "âœ” The **inner dimensions must match**: the **number of columns** of A = **number of rows** of B.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Œ **Matrix Product Element-wise**\n",
    "\n",
    "Each element $c_{ij}$ in $C$ is:\n",
    "\n",
    "$$\n",
    "c_{ij} = \\sum_{p=1}^{k} a_{ip} b_{pj}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **2ï¸âƒ£ Practical Example**\n",
    "\n",
    "**Example:**\n",
    "A: (2 Ã— 3)\n",
    "B: (3 Ã— 4)\n",
    "\n",
    "Result: C is (2 Ã— 4)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "A = torch.rand(2, 3)\n",
    "B = torch.rand(3, 4)\n",
    "\n",
    "C = torch.matmul(A, B)\n",
    "print(C.shape)  # torch.Size([2, 4])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ **3ï¸âƒ£ Rules in Plain Language**\n",
    "\n",
    "| Rule             | Description                     |\n",
    "| ---------------- | ------------------------------- |\n",
    "| Inner Dimensions | Must match (`A.cols == B.rows`) |\n",
    "| Output Shape     | `(A.rows, B.cols)`              |\n",
    "| Non-Commutative  | `AB` â‰  `BA` in general          |\n",
    "| Associative      | `(AB)C = A(BC)`                 |\n",
    "| Distributive     | `A(B + C) = AB + AC`            |\n",
    "| Scalar Multiple  | `k(AB) = (kA)B = A(kB)`         |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” **4ï¸âƒ£ Visual Intuition**\n",
    "\n",
    "Think of multiplying:\n",
    "\n",
    "* **Rows of A** by **columns of B**.\n",
    "\n",
    "**Example:**\n",
    "If A is (2 Ã— 3) â†’ it has 2 row vectors of length 3.\n",
    "If B is (3 Ã— 4) â†’ it has 4 column vectors of length 3.\n",
    "Each output element is a dot product between a row of A and a column of B.\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ **5ï¸âƒ£ Common Pitfalls**\n",
    "\n",
    "ðŸš« **Confusing `*` and `@`**:\n",
    "`*` is element-wise, `@` is matrix product.\n",
    "\n",
    "ðŸš« **Shape Mismatch**:\n",
    "If `A` is (3 Ã— 2) and `B` is (3 Ã— 4) â†’ cannot multiply! Must transpose or reshape.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **6ï¸âƒ£ Best Practices**\n",
    "\n",
    "âœ” Always check `A.shape` and `B.shape` before `A @ B`.\n",
    "\n",
    "âœ” Use `.T` to transpose if needed:\n",
    "\n",
    "```python\n",
    "B_T = B.T  # or B.transpose(0, 1)\n",
    "```\n",
    "\n",
    "âœ” For batched matmuls:\n",
    "\n",
    "* Use `torch.bmm` for `(b Ã— m Ã— k)` @ `(b Ã— k Ã— n)`.\n",
    "* Or `torch.matmul` â€” supports broadcasting for batch dimensions.\n",
    "\n",
    "âœ” Use `torch.einsum` for complex contraction:\n",
    "\n",
    "```python\n",
    "torch.einsum('ik,kj->ij', A, B)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¬ **7ï¸âƒ£ Special Notes**\n",
    "\n",
    "* **Square Matrices:**\n",
    "  If A and B are both (n Ã— n) â†’ multiplication is valid.\n",
    "\n",
    "* **Dot Product:**\n",
    "  A vector dot product is a special case:\n",
    "\n",
    "  $$\n",
    "  \\text{dot}(x, y) = x^T y\n",
    "  $$\n",
    "\n",
    "* **Outer Product:**\n",
    "\n",
    "  $$\n",
    "  uv^T = \\text{matrix}\n",
    "  \\quad (m \\times 1) \\times (1 \\times n) = m \\times n\n",
    "  $$\n",
    "\n",
    "---\n",
    "## âœ… **Summary â€” Rules Cheat Sheet**\n",
    "\n",
    "| Concept       | Rule                                           |\n",
    "| ------------- | ---------------------------------------------- |\n",
    "| Shapes        | `(m Ã— k)` @ `(k Ã— n)` â†’ `(m Ã— n)`              |\n",
    "| Order         | `AB â‰  BA`                                      |\n",
    "| Associative   | `(AB)C = A(BC)`                                |\n",
    "| Dot product   | Special case: `(1 Ã— k)` @ `(k Ã— 1)` â†’ scalar   |\n",
    "| Outer product | `(m Ã— 1)` @ `(1 Ã— n)` â†’ `(m Ã— n)`              |\n",
    "| Broadcasting  | Not automatic â€” only batch dim can broadcast   |\n",
    "| Operation     | Use `@` or `torch.matmul` for correct behavior |\n",
    "\n",
    "---\n",
    "## âœ…**Golden Tip**\n",
    "\n",
    "**Before multiplying matrices:**\n",
    "\n",
    "1. Print their shapes.\n",
    "2. Double-check the inner dimensions.\n",
    "3. Use `.T` wisely.\n",
    "4. Write down the shape math on paper if unsure!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "4e4bb600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape[1]== B.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "109021c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[376], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      2\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;66;03m#shape (3, 2)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      6\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;66;03m#shape (3, 2)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32) #shape (3, 2)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]], dtype=torch.float32) #shape (3, 2)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "72b3b914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_A:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "\n",
      "tensor_A Transposed:\n",
      "tensor([[1., 3., 5.],\n",
      "        [2., 4., 6.]])\n",
      "\n",
      "tensor_B:\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n",
      "\n",
      "tensor_B Transposed:\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"tensor_A:\")\n",
    "print(tensor_A)\n",
    "print(\"\\ntensor_A Transposed:\")\n",
    "print(tensor_A.T)\n",
    "print(\"\\ntensor_B:\")\n",
    "print(tensor_B)\n",
    "print(\"\\ntensor_B Transposed:\")\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "f858a3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "result = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(result)\n",
    "print(result.shape)  # torch.Size([3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "6bb571fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_A shape: torch.Size([3, 2]), tensor_B shape: torch.Size([3, 2])\n",
      "tensor_A Transposed shape: torch.Size([2, 3]), tensor_B Transposed shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor_A shape: {tensor_A.shape}, tensor_B shape: {tensor_B.shape}\")\n",
    "print(f\"tensor_A Transposed shape: {tensor_A.T.shape}, tensor_B Transposed shape: {tensor_B.T.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "153d71e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_A @ tensor_B.T)\n",
    "print((tensor_A @ tensor_B.T).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49e7e9",
   "metadata": {},
   "source": [
    "## **MEAN,MAX,MIN,AGGREGATION  ........**\n",
    "\n",
    "| Category          | PyTorch Ops                                                              |\n",
    "| ----------------- | ------------------------------------------------------------------------ |\n",
    "| Summation         | `torch.sum`, `torch.cumsum`, `torch.nansum`                              |\n",
    "| Product           | `torch.prod`, `torch.cumprod`                                            |\n",
    "| Mean & Statistics | `torch.mean`, `torch.std`, `torch.var`, `torch.median`, `torch.quantile` |\n",
    "| Min/Max           | `torch.min`, `torch.max`, `torch.amin`, `torch.amax`                     |\n",
    "| Argmin/Argmax     | `torch.argmin`, `torch.argmax`                                           |\n",
    "| Norms             | `torch.norm`                                                             |\n",
    "| Logical           | `torch.any`, `torch.all`                                                 |\n",
    "| Count nonzero     | `torch.count_nonzero`                                                    |\n",
    "| Unique            | `torch.unique`                                                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "6025e14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x:\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]])\n",
      "\n",
      "Sum of all elements in x: tensor(45.)\n",
      "\n",
      "Sum along columns (dim=0): tensor([ 5.,  7.,  9., 11., 13.])\n",
      "\n",
      "Sum along rows (dim=1): tensor([10., 35.])\n",
      "\n",
      "Sum along rows (dim=1) with keepdim=True:\n",
      " tensor([[10.],\n",
      "        [35.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.sum(input, dim=None, keepdim=False)\n",
    "x = torch.arange(10).reshape(2, 5).float()  # Create a 2x5 tensor with values from 0 to 9\n",
    "print(\"Original tensor x:\")\n",
    "print(x)\n",
    "\n",
    "# Sum all elements in the tensor\n",
    "total_sum = torch.sum(x)\n",
    "print(\"\\nSum of all elements in x:\", total_sum)  # Output: 45.0\n",
    "\n",
    "# Sum along columns (dim=0): sums over rows for each column\n",
    "sum_dim0 = torch.sum(x, dim=0)\n",
    "print(\"\\nSum along columns (dim=0):\", sum_dim0)  # Output: tensor([ 5.,  7.,  9., 11., 13.])\n",
    "\n",
    "# Sum along rows (dim=1): sums over columns for each row\n",
    "sum_dim1 = torch.sum(x, dim=1)\n",
    "print(\"\\nSum along rows (dim=1):\", sum_dim1)  # Output: tensor([10., 35.])\n",
    "\n",
    "# Sum along rows (dim=1) but keep the dimension (result is column vector)\n",
    "sum_dim1_keepdim = torch.sum(x, dim=1, keepdim=True)\n",
    "print(\"\\nSum along rows (dim=1) with keepdim=True:\\n\", sum_dim1_keepdim)  # Output: tensor([[10.], [35.]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "44aba254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative sum of all elements (flattened): tensor([ 0.,  1.,  3.,  6., 10., 15., 21., 28., 36., 45.])\n",
      "\n",
      "Cumulative sum along columns (dim=0):\n",
      " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 5.,  7.,  9., 11., 13.]])\n",
      "\n",
      "Cumulative sum along rows (dim=1):\n",
      " tensor([[ 0.,  1.,  3.,  6., 10.],\n",
      "        [ 5., 11., 18., 26., 35.]])\n"
     ]
    }
   ],
   "source": [
    "# Cumulative sum of all elements (flattened)\n",
    "cumsum_all = torch.cumsum(x.flatten(), dim=0)\n",
    "print(\"Cumulative sum of all elements (flattened):\", cumsum_all)\n",
    "\n",
    "# Cumulative sum along columns (dim=0)\n",
    "cumsum_dim0 = torch.cumsum(x, dim=0)\n",
    "print(\"\\nCumulative sum along columns (dim=0):\\n\", cumsum_dim0)\n",
    "\n",
    "# Cumulative sum along rows (dim=1)\n",
    "cumsum_dim1 = torch.cumsum(x, dim=1)\n",
    "print(\"\\nCumulative sum along rows (dim=1):\\n\", cumsum_dim1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "f622c4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor with NaNs:\n",
      "tensor([[0., 1., nan, 3., 4.],\n",
      "        [5., 6., 7., nan, 9.]])\n",
      "\n",
      "Sum of all elements in x_with_nan (ignoring NaNs): tensor(35.)\n",
      "\n",
      "Sum along columns (dim=0, ignoring NaNs): tensor([ 5.,  7.,  7.,  3., 13.])\n",
      "\n",
      "Sum along rows (dim=1, ignoring NaNs): tensor([ 8., 27.])\n"
     ]
    }
   ],
   "source": [
    "# torch.nansum(input, dim=None, keepdim=False)\n",
    "# nansum computes the sum of all elements, treating NaNs as zero\n",
    "\n",
    "x_with_nan = torch.tensor([[0., 1., float('nan'), 3., 4.],\n",
    "                           [5., 6., 7., float('nan'), 9.]])\n",
    "\n",
    "print(\"Tensor with NaNs:\")\n",
    "print(x_with_nan)\n",
    "\n",
    "nansum_total = torch.nansum(x_with_nan)\n",
    "print(\"\\nSum of all elements in x_with_nan (ignoring NaNs):\", nansum_total)\n",
    "\n",
    "nansum_dim0 = torch.nansum(x_with_nan, dim=0)\n",
    "print(\"\\nSum along columns (dim=0, ignoring NaNs):\", nansum_dim0)\n",
    "\n",
    "nansum_dim1 = torch.nansum(x_with_nan, dim=1)\n",
    "print(\"\\nSum along rows (dim=1, ignoring NaNs):\", nansum_dim1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "8956f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x:\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]])\n",
      "\n",
      "Mean of all elements in x: tensor(4.5000)\n",
      "\n",
      "Mean along columns (dim=0): tensor([2.5000, 3.5000, 4.5000, 5.5000, 6.5000])\n",
      "\n",
      "Mean along rows (dim=1): tensor([2., 7.])\n",
      "\n",
      "Mean along rows (dim=1) with keepdim=True:\n",
      " tensor([[2.],\n",
      "        [7.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.mean(input, dim=None, keepdim=False, dtype=None)\n",
    "x = torch.arange(10).reshape(2, 5).float()  # 2x5 tensor with values 0-9\n",
    "print(\"Original tensor x:\")\n",
    "print(x)\n",
    "\n",
    "# Mean of all elements\n",
    "mean_total = torch.mean(x)\n",
    "print(\"\\nMean of all elements in x:\", mean_total)  # Output: 4.5\n",
    "\n",
    "# Mean along columns (dim=0)\n",
    "mean_dim0 = torch.mean(x, dim=0)\n",
    "print(\"\\nMean along columns (dim=0):\", mean_dim0)  # Output: tensor([2.5, 3.5, 4.5, 5.5, 6.5])\n",
    "\n",
    "# Mean along rows (dim=1)\n",
    "mean_dim1 = torch.mean(x, dim=1)\n",
    "print(\"\\nMean along rows (dim=1):\", mean_dim1)  # Output: tensor([2., 7.])\n",
    "\n",
    "# Mean along rows (dim=1) with keepdim=True\n",
    "mean_dim1_keepdim = torch.mean(x, dim=1, keepdim=True)\n",
    "print(\"\\nMean along rows (dim=1) with keepdim=True:\\n\", mean_dim1_keepdim)  # Output: tensor([[2.], [7.]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "a1e4fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x:\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]])\n",
      "\n",
      "Standard deviation of all elements in x: tensor(3.0277)\n",
      "Variance of all elements in x: tensor(9.1667)\n",
      "\n",
      "Standard deviation along columns (dim=0): tensor([3.5355, 3.5355, 3.5355, 3.5355, 3.5355])\n",
      "Variance along columns (dim=0): tensor([12.5000, 12.5000, 12.5000, 12.5000, 12.5000])\n",
      "\n",
      "Standard deviation along rows (dim=1): tensor([1.5811, 1.5811])\n",
      "Variance along rows (dim=1): tensor([2.5000, 2.5000])\n"
     ]
    }
   ],
   "source": [
    "# torch.std(input, dim=None, unbiased=True, keepdim=False)\n",
    "# torch.var(input, dim=None, unbiased=True, keepdim=False)\n",
    "\n",
    "print(\"Original tensor x:\")\n",
    "print(x)\n",
    "\n",
    "# Standard deviation of all elements\n",
    "std_total = torch.std(x)\n",
    "print(\"\\nStandard deviation of all elements in x:\", std_total)\n",
    "\n",
    "# Variance of all elements\n",
    "var_total = torch.var(x)\n",
    "print(\"Variance of all elements in x:\", var_total)\n",
    "\n",
    "# Standard deviation along columns (dim=0)\n",
    "std_dim0 = torch.std(x, dim=0)\n",
    "print(\"\\nStandard deviation along columns (dim=0):\", std_dim0)\n",
    "\n",
    "# Variance along columns (dim=0)\n",
    "var_dim0 = torch.var(x, dim=0)\n",
    "print(\"Variance along columns (dim=0):\", var_dim0)\n",
    "\n",
    "# Standard deviation along rows (dim=1)\n",
    "std_dim1 = torch.std(x, dim=1)\n",
    "print(\"\\nStandard deviation along rows (dim=1):\", std_dim1)\n",
    "\n",
    "# Variance along rows (dim=1)\n",
    "var_dim1 = torch.var(x, dim=1)\n",
    "print(\"Variance along rows (dim=1):\", var_dim1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "6eaf99f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x:\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]])\n",
      "Median of all elements in x: tensor(4.)\n",
      "Median along columns (dim=0): tensor([0., 1., 2., 3., 4.])\n",
      "Indices of medians along columns (dim=0): tensor([0, 0, 0, 0, 0])\n",
      "Median along rows (dim=1): tensor([2., 7.])\n",
      "Indices of medians along rows (dim=1): tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"Original tensor x:\")\n",
    "print(x)\n",
    "# torch.median(input) returns the median of all elements (flattened)\n",
    "median_total = torch.median(x)\n",
    "print(\"Median of all elements in x:\", median_total)\n",
    "\n",
    "# torch.median(input, dim=0) returns (values, indices) along columns\n",
    "median_dim0, indices_dim0 = torch.median(x, dim=0)\n",
    "print(\"Median along columns (dim=0):\", median_dim0)\n",
    "print(\"Indices of medians along columns (dim=0):\", indices_dim0)\n",
    "\n",
    "# torch.median(input, dim=1) returns (values, indices) along rows\n",
    "median_dim1, indices_dim1 = torch.median(x, dim=1)\n",
    "print(\"Median along rows (dim=1):\", median_dim1)\n",
    "print(\"Indices of medians along rows (dim=1):\", indices_dim1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "f76a20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x:\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]])\n",
      "\n",
      "Min of all elements in x: tensor(0.)\n",
      "Max of all elements in x: tensor(9.)\n",
      "\n",
      "Min along columns (dim=0): tensor([0., 1., 2., 3., 4.])\n",
      "Indices of min along columns (dim=0): tensor([0, 0, 0, 0, 0])\n",
      "Max along columns (dim=0): tensor([5., 6., 7., 8., 9.])\n",
      "Indices of max along columns (dim=0): tensor([1, 1, 1, 1, 1])\n",
      "\n",
      "Amin of all elements in x: tensor(0.)\n",
      "Amax of all elements in x: tensor(9.)\n",
      "\n",
      "Argmin of all elements in x (flattened): tensor(0)\n",
      "Argmax of all elements in x (flattened): tensor(9)\n",
      "\n",
      "Argmin along columns (dim=0): tensor([0, 0, 0, 0, 0])\n",
      "Argmax along columns (dim=0): tensor([1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.min and torch.max (two forms)\n",
    "\n",
    "print(\"Original tensor x:\")\n",
    "print(x)\n",
    "\n",
    "# Scalar min and max (over all elements)\n",
    "min_total = torch.min(x)\n",
    "max_total = torch.max(x)\n",
    "print(\"\\nMin of all elements in x:\", min_total)\n",
    "print(\"Max of all elements in x:\", max_total)\n",
    "\n",
    "# Min and max along columns (dim=0): returns (values, indices)\n",
    "min_dim0, min_indices_dim0 = torch.min(x, dim=0)\n",
    "max_dim0, max_indices_dim0 = torch.max(x, dim=0)\n",
    "print(\"\\nMin along columns (dim=0):\", min_dim0)\n",
    "print(\"Indices of min along columns (dim=0):\", min_indices_dim0)\n",
    "print(\"Max along columns (dim=0):\", max_dim0)\n",
    "print(\"Indices of max along columns (dim=0):\", max_indices_dim0)\n",
    "\n",
    "# torch.amin and torch.amax (value only, no indices)\n",
    "amin_total = torch.amin(x)\n",
    "amax_total = torch.amax(x)\n",
    "print(\"\\nAmin of all elements in x:\", amin_total)\n",
    "print(\"Amax of all elements in x:\", amax_total)\n",
    "\n",
    "# torch.argmin and torch.argmax\n",
    "argmin_total = torch.argmin(x)\n",
    "argmax_total = torch.argmax(x)\n",
    "print(\"\\nArgmin of all elements in x (flattened):\", argmin_total)\n",
    "print(\"Argmax of all elements in x (flattened):\", argmax_total)\n",
    "\n",
    "# Argmin/argmax along columns (dim=0)\n",
    "argmin_dim0 = torch.argmin(x, dim=0)\n",
    "argmax_dim0 = torch.argmax(x, dim=0)\n",
    "print(\"\\nArgmin along columns (dim=0):\", argmin_dim0)\n",
    "print(\"Argmax along columns (dim=0):\", argmax_dim0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad459196",
   "metadata": {},
   "source": [
    "## **1ï¸. Reshaping â€” `torch.reshape` & `.view`**\n",
    "\n",
    "### ðŸ“˜ **Theory**\n",
    "\n",
    "Reshaping reinterprets the same **underlying data buffer** with a **new shape** â€” no data copy if possible.\n",
    "\n",
    "* `tensor.reshape(shape)`\n",
    "* `tensor.view(shape)` (older style, stricter: works only if the tensor is contiguous in memory)\n",
    "\n",
    "**Condition:**\n",
    "The **total number of elements** must stay the same.\n",
    "\n",
    "$$\n",
    "\\text{Shape A} \\quad \\Rightarrow \\quad \\text{Shape B} \\quad \n",
    "\\text{only if} \\quad \\prod A = \\prod B\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "944e9e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1.,11.)\n",
    "print(x.shape)\n",
    "\n",
    "y = x.reshape(5,2)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "439574aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(2, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "1e18e6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]])\n"
     ]
    }
   ],
   "source": [
    "# .view() errors out if the tensor is not contiguous â†’ fix with .contiguous().\n",
    "\n",
    "z= x.view(5,2)  # Reshape x to 2 rows, automatically infer columns\n",
    "print(z)\n",
    "z[0][1]=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "98b76b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., 10.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]])\n",
      "tensor([ 1., 10.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n"
     ]
    }
   ],
   "source": [
    "print(z)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "11e7d51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0962, 0.1468, 0.9028, 0.8003, 0.7529]],\n",
      "\n",
      "         [[0.0500, 0.7613, 0.8566, 0.3957, 0.9235]],\n",
      "\n",
      "         [[0.6141, 0.1628, 0.9465, 0.3997, 0.9280]]]])\n",
      "torch.Size([1, 3, 1, 5])\n",
      "tensor([[0.0962, 0.1468, 0.9028, 0.8003, 0.7529],\n",
      "        [0.0500, 0.7613, 0.8566, 0.3957, 0.9235],\n",
      "        [0.6141, 0.1628, 0.9465, 0.3997, 0.9280]])\n",
      "torch.Size([3, 5])\n",
      "tensor([[[[0.0962, 0.1468, 0.9028, 0.8003, 0.7529]],\n",
      "\n",
      "         [[0.0500, 0.7613, 0.8566, 0.3957, 0.9235]],\n",
      "\n",
      "         [[0.6141, 0.1628, 0.9465, 0.3997, 0.9280]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 1, 5)\n",
    "print(x)\n",
    "print(x.shape)  # torch.Size([1, 3, 1, 5])\n",
    "\n",
    "y = torch.squeeze(x)\n",
    "print(y)\n",
    "print(y.shape)  # torch.Size([3, 5])\n",
    "\n",
    "# Only squeeze dim=2 (which is size 1)\n",
    "torch.squeeze(x, dim=2).shape  # (1, 3, 5)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "86e61062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x: tensor([1, 2, 3])\n",
      "Unsqueezed tensor y (dim=0): tensor([[1, 2, 3]])\n",
      "Unsqueezed tensor z (dim=1): tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])  # (3,)\n",
    "y = torch.unsqueeze(x, dim=0)  # (1, 3)\n",
    "z = torch.unsqueeze(x, dim=1)  # (3, 1)\n",
    "print(\"Original tensor x:\", x)\n",
    "print(\"Unsqueezed tensor y (dim=0):\", y)\n",
    "print(\"Unsqueezed tensor z (dim=1):\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "4fc5c53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([3, 4])\n",
    "c = torch.stack([a, b], dim=0)\n",
    "print(c)  # [[1, 2], [3, 4]] â†’ shape (2, 2)\n",
    "\n",
    "d = torch.stack([a, b], dim=1)\n",
    "print(d)  # [[1, 3], [2, 4]] â†’ shape (2, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334fcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e21ec69",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae34922",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library.\n",
    "\n",
    "And because of this, PyTorch has functionality to interact with it.\n",
    "\n",
    "* Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "c92a4ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # warning: when converting from numpy -> pytorch, pytorch reflects numpy's default datatype of float64 unless specified otherwise\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "c4e4e8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to `tensor`?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "796afc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "66700d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tesnor, what happens to `numpy_tensor`?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5e174",
   "metadata": {},
   "source": [
    "# **Reproducbility**\n",
    "- Reproducibility means that someone (including you) can run the same code or experiment again and get the same result, within a reasonable margin of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "4d823e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor A:\n",
      "tensor([[0.5343, 0.3798, 0.8840, 0.8208],\n",
      "        [0.9589, 0.8026, 0.4933, 0.6605],\n",
      "        [0.7398, 0.1719, 0.5888, 0.0170]])\n",
      "Random Tensor B:\n",
      "tensor([[0.0110, 0.7976, 0.9729, 0.5154],\n",
      "        [0.4507, 0.6798, 0.6274, 0.1614],\n",
      "        [0.4737, 0.8413, 0.8910, 0.3652]])\n",
      "- Are they equal??\n",
      " tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor_a =torch.rand(3,4)\n",
    "random_tensor_b =torch.rand(3,4)\n",
    "\n",
    "\n",
    "print(\"Random Tensor A:\")\n",
    "print(random_tensor_a)\n",
    "print(\"Random Tensor B:\")\n",
    "print(random_tensor_b)\n",
    "\n",
    "print(\"- Are they equal??\\n\", random_tensor_a== random_tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "379c61db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "Random Tensor D:\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "- Are they equal??\n",
      " tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED=42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_c= torch.rand(3,4)\n",
    "random_tensor_d = torch.rand(3,4)\n",
    "print(\"Random Tensor C:\")\n",
    "print(random_tensor_c)\n",
    "print(\"Random Tensor D:\")\n",
    "print(random_tensor_d)\n",
    "\n",
    "print(\"- Are they equal??\\n\", random_tensor_c== random_tensor_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "d348f13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "Random Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "- Are they equal??\n",
      " tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED=42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_c= torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_d = torch.rand(3,4)\n",
    "\n",
    "print(\"Random Tensor C:\")\n",
    "print(random_tensor_c)\n",
    "print(\"Random Tensor D:\")\n",
    "print(random_tensor_d)\n",
    "\n",
    "print(\"- Are they equal??\\n\", random_tensor_c== random_tensor_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "b4436d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to 42.\n",
      "Random Seed E:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "Random Seed F:\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "- Are they equal??\n",
      " tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "\n",
    "    # Force deterministic operations\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    print(f\"[INFO] Random seed set to {seed}.\")\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "random_seed_e=torch.rand(3,4)\n",
    "random_seed_f= torch.rand(3,4)\n",
    "\n",
    "print(\"Random Seed E:\")\n",
    "print(random_seed_e)\n",
    "print(\"Random Seed F:\")\n",
    "print(random_seed_f)\n",
    "print(\"- Are they equal??\\n\", random_seed_e== random_seed_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "93725139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "[INFO] CUDA Runtime Version: 12.1\n",
      "[INFO] cuDNN Version: 90100\n",
      "[INFO] PyTorch Version: 2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "def get_device(prefer_gpu=True, index=0, verbose=True):\n",
    "    \"\"\"\n",
    "    Get the computing device (GPU if available and preferred, else CPU),\n",
    "    and print concise hardware info.\n",
    "    \"\"\"\n",
    "    if prefer_gpu and torch.cuda.is_available():\n",
    "        device = torch.device(f'cuda:{index}')\n",
    "        if verbose:\n",
    "            print(f\"[INFO] Using GPU {index}: {torch.cuda.get_device_name(index)}\")\n",
    "            print(f\"[INFO] CUDA Runtime Version: {torch.version.cuda}\")\n",
    "            print(f\"[INFO] cuDNN Version: {torch.backends.cudnn.version()}\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        if verbose:\n",
    "            print(\"[INFO] Using CPU.\")\n",
    "    if verbose:\n",
    "        print(f\"[INFO] PyTorch Version: {torch.__version__}\")\n",
    "    return device\n",
    "\n",
    "# Example usage\n",
    "device = get_device(prefer_gpu=True, index=0, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "efc66adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3, device=device)\n",
    "\n",
    "y = torch.randn(3, 3)\n",
    "y = y.to(device)\n",
    "\n",
    "z = x + y\n",
    "print(z.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "75e776f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "\n",
    "y = torch.randn(3, 3)\n",
    "\n",
    "z = x + y\n",
    "print(z.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "b70cbe5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[578], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(z\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3, device=device)\n",
    "\n",
    "y = torch.randn(3, 3)\n",
    "\n",
    "z = x + y\n",
    "print(z.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "68965c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device of x: cuda:0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[580], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice of x: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m transform_numpy\u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert tensor to NumPy array\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print(f\"Device of x: {x.device}\")\n",
    "transform_numpy= x.numpy()  # Convert tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "9db4ce42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6973659 , -1.8688258 , -0.8831874 ],\n",
       "       [-1.6627042 , -0.43243223,  0.9504958 ],\n",
       "       [ 0.6620458 ,  0.04456767,  0.57203025]], dtype=float32)"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_numpy_correct= x.to(device=\"cpu\").numpy()\n",
    "transform_numpy_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "bf4eea32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6973659 , -1.8688258 , -0.8831874 ],\n",
       "       [-1.6627042 , -0.43243223,  0.9504958 ],\n",
       "       [ 0.6620458 ,  0.04456767,  0.57203025]], dtype=float32)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_numpy_correct= x.cpu().numpy()\n",
    "transform_numpy_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7d43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3070",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
